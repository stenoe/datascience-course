{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "yellow-vector",
   "metadata": {},
   "source": [
    "# Basic example with Jupyter, Python and some R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-irrigation",
   "metadata": {},
   "source": [
    "Some motivations first...\n",
    "\n",
    "Today, Jupyter notebooks are used in data science, astronomy, biology, gene research, engineering, teaching, and more. A very interesting information on them was published some years ago in [Nature](https://www.nature.com/articles/d41586-018-07196-1) and an introduction to Jupyter notebooks from one of its creators. Here is a lecture of [Fernando Peréz](https://bids.berkeley.edu/events/project-jupyter-architecture-and-evolution-open-platform-modern-data-science) how Jupyter notebooks came into place and what is done with them in science. And for more enjoyment, here's a story on [notebooks](https://www.theatlantic.com/science/archive/2018/04/the-scientific-paper-is-obsolete/556676/) in a wider context and why scientists became software developers and why notebooks are \"computational essays\".\n",
    "\n",
    "<span style='color:DarkRed'>Don't get too distracted, you can easily spent some hours on reading, listening and exploring :)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-coalition",
   "metadata": {
    "tags": []
   },
   "source": [
    "### How to use this notebook?\n",
    "\n",
    "This is a computational document, you are supposed to execute the code and see live what happens. Learning by doing :)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-failing",
   "metadata": {},
   "source": [
    "## Hands on -- what we're gonna do?\n",
    "\n",
    "Basically, in almost all scientific fields we have some data, some analysis of that data, we develop understanding and new ideas, in an iterative process and eventually there will spin off some publications from that process.\n",
    "\n",
    "Notebooks give us a tool at hand to perform this in one place. No jumping between different programs, need a short calculation, just do right away. See a new feature of data, just write some thoughts right away.\n",
    "\n",
    "In a short sentence, we are building workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-september",
   "metadata": {},
   "source": [
    "### Solving a basic problem\n",
    "\n",
    "the usual workflow is:\n",
    "\n",
    "1. load or create some data\n",
    "2. visualise the data\n",
    "3. create a hypothesis\n",
    "4. test the hypothesis\n",
    "\n",
    "In time of the corona pandemia, lets check some data on the latest test results in Estonia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-notion",
   "metadata": {},
   "source": [
    "#### Import needed libraries\n",
    "\n",
    "Python and many other programming languages use libraries or packages the can be loaded if they are needed. For data science Python has the [pandas](https://pandas.pydata.org) dataframe tool. Additionally, we may need some mathematical transformations which we can load from the [numpy](https://numpy.org) library for fundamental scientific computing and of course, we like to visualise our data in a convenient way using the [matplotlib](https://matplotlib.org/stable/index.html) packages. \n",
    "\n",
    "To run a code cell like the one below, select the cell and press ```[CTRL] + [ENTER]``` or use a button to execute the code in the cell. Depending if You use Jupyter lab or notebook these buttons are provided on top of the actual notebook or you can run cells via menu entries.\n",
    "\n",
    "In the code cell that follows we import these packages and give shorter names to them. Doing so, makes our typing work a bit shorter since we can refer to fuunctions inside the package pandas via pd, in numpy via np, and the long matplotlib.pyplot is fianlly a short plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-excess",
   "metadata": {},
   "source": [
    "#### Load the data\n",
    "\n",
    "In this step, we use the pandas function \n",
    "\n",
    "```Python\n",
    "pd.read_csv('filename')\n",
    "```\n",
    "\n",
    "to read the data from the file ```teste-pevas.csv```which we have downloaded before from the [Koroonakaart.ee](https://koroonakaart.ee/et) website. \n",
    "\n",
    "This is a very common task and pandas offers read functions for many [data formats](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('teste-pevas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-following",
   "metadata": {},
   "source": [
    "#### Visualise the data\n",
    "\n",
    "We have stored the dataframe into the variable ```data``` and if we enter this name and execute the cell, Jupyter notebooks show us the contents of the dataframe in a readable way. Because data is typically lengthly, it already takes care and shortens the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-mason",
   "metadata": {},
   "source": [
    "From this, we allready get informations. Our data contains dates and times of tests, the number of posistives and negatives per day and the percentage of positive tests per day. Further, we get information on the dimensions of our data. \n",
    "\n",
    "The first column without a header text is the index.\n",
    "\n",
    "To access a column in the dataframe, we can use this header text to select this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-estonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Positiivsete testide %']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-transcription",
   "metadata": {},
   "source": [
    "Here, we get also information on our data, we see that the type of data is ```float64```, so a floating point number with 64 bit represenation in the computer. In mathematics, this is called a Real number.\n",
    "\n",
    "There are more pandas functions available to get informations on the dataframe and ```info()``` gives some overview on all types in the dataset with Dtype, the \\# to access columns via numbers, the used memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-neutral",
   "metadata": {},
   "source": [
    "To access a column by its index number, the function ```iloc[]``` exists, it can access both, rows and columns and the notation below selects all rows ```:``` and the third column. This is essentially the same as using the header text (see above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-forwarding",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-sacrifice",
   "metadata": {},
   "source": [
    "#### Visualise the data graphically\n",
    "\n",
    "Pandas has also great possibilities to plot graphics right out of the box. Similar to the table respresentation a call to\n",
    "\n",
    "```python\n",
    "data.plot()\n",
    "```\n",
    "\n",
    "will plot the whole dataframe at once. We add the matplotlib command \n",
    "\n",
    "```python\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "to avoid output of information on the plot. If you want to see this output, just use ```#``` (the comment sign) and write\n",
    "\n",
    "```python\n",
    "data.plot()\n",
    "#plt.show()\n",
    "```\n",
    "\n",
    "to comment out the last command and re-run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-saver",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\">\n",
    "A note on comments. You can use the hash ( # ) symbol in code cells to enter text that helps you comment your code. It is a good idea to write some comments to code cells so you can remember what you made and others can understand some constructs.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-twins",
   "metadata": {},
   "source": [
    "Looking at the result, this command has plotted all numerical data, positive, negative and percentage but not the date and time. This makes of course sense because a datetime object does not have a natural representation as a single number. The x axis was automatically chosen to be the index of the datframe. \n",
    "\n",
    "In the next step, we use the datetime object as x-axis and the percentage as y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-gazette",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the column with percentage of positives test against the date\n",
    "\n",
    "data.plot(x='DateTime', y='Positiivsete testide %')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-defense",
   "metadata": {},
   "source": [
    "In this output, we can see that we got what we wanted but the x-axis tick labels all overlap. This makes it useless because we  can not read anymore the dates and we loose information on this visualisation. \n",
    "\n",
    "We can, fortunately, tell matplotlib that we want to turn the labes by 45° counterclockwise. Using ```plt```, remeber we loaded the matplotlib pyplot package and gave it this short name, we can access the last plot and use the function that deals with the tickmarks and labels on the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-margin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the column with percentage of positives test against the date\n",
    "\n",
    "data.plot(x='DateTime', y='Positiivsete testide %', figsize=(10,5))\n",
    "plt.xticks(rotation=45) # rotate the x tick labels by 45°\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-nature",
   "metadata": {},
   "source": [
    "Now, we can see also again the dates. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-webster",
   "metadata": {},
   "source": [
    "### Creating some hypothesis\n",
    "\n",
    "If we follow the data in the graph above the latest rise in the percentage of positive tests is likely to follow an exponental growth pattern. So we can hypothesise that the growth in percentage of positive tests during the last 1.5 months is described by:\n",
    "\n",
    "$$y =  a + b e^{c t}$$\n",
    "\n",
    "where $a$ is some offset paramter because the last part of the curve start at some values around 10%. $b$ and $c$ are parameters we may estimate and $t$ is the time in days.\n",
    "\n",
    "\n",
    "How could we test this hypothesis? First, we may select the data starting from some time in January until the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['DateTime']>= '2021-01-20'].plot(x='DateTime', y='Positiivsete testide %', style='.')\n",
    "plt.xticks(rotation=45) # rotate the x tick labels by 45°\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-halloween",
   "metadata": {},
   "source": [
    "We can see that in this time range, the percentage of positive tests was about 10% in the third week of January and has been growing with increasing pace. \n",
    "\n",
    "Now, lets create data vectors from our dataframe and we store the values of the positive tests percentage into a numpy array. Then, we use the length of that array to determine the number of days since our chosen date on 2021-01-20. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-phase",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the y values vector\n",
    "y = data[data['DateTime']>= '2021-01-20']['Positiivsete testide %'].values\n",
    "\n",
    "# and some x values\n",
    "x = np.arange(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-butterfly",
   "metadata": {},
   "source": [
    "#### Combining languages in one Jupyter notebook - How to use R\n",
    "\n",
    "Here, we use a really good feature of Jypyter. We have the possibility to use different calculation kernels. So far, we used Python but [R](https://www.r-project.org) is pretty good in data fitting, so why not to use this and load an extension with which we can make this task in R.\n",
    "\n",
    "The magic word is ```%load_ext  extension``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use R for the fit\n",
    "\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-rescue",
   "metadata": {},
   "source": [
    "In the next cell, we now tell to the notebook what variables will be passed over to the R calculation kernel and in which variable we want to get back our result. Thi is done by the flags ```-i``` and ```-o``` for \"in\" and \"out\" and the code:\n",
    "\n",
    "```python\n",
    "%%R -i y,x -o fitc\n",
    "```\n",
    "\n",
    "reads as, pass on the variables y and x to the R kernel, do whatever we asked and give us back the result in fitc.\n",
    "\n",
    "The next step defines a non-linear exponential model with an offset (as described before), makes the fit and shows the results, we check a residual fit to see if our hypothesised relations matches and the fit is valid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-zoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i y,x -o fitc\n",
    "\n",
    "ylm = nls(y ~ a + b * exp(c*x),start=list(a=10., b=0.1, c=0.1))\n",
    "fitc = coef(ylm)\n",
    "print(summary(ylm))\n",
    "\n",
    "plot(resid(ylm))\n",
    "abline(h=0, col='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-destiny",
   "metadata": {},
   "source": [
    "The results above tell us two things, first that the estimates for the parameters $a$ and $c$ are significant, i.e. they are good estimators. However, the parameter $b$ has an insignificant estimator and therefore the model fits the data not perfectly. \n",
    "\n",
    "The second important outcome is that the model rediduals are randomly distributed and there is no heteroscedasticity, i.e. the residuals are beside the one value in the range of -3 to 2. \n",
    "\n",
    "Do let's look at the coefficients we got back from the R subroutine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-shower",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fitc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-titanium",
   "metadata": {},
   "source": [
    "Now we use them to create a fitted plot  and overly it with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-adaptation",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yfit = fitc[0] + fitc[1] * np.exp(fitc[2] * x)\n",
    "\n",
    "plt.plot(x, y, 'o', label='data')\n",
    "plt.plot(x, yfit, label='fit', color='orange', lw=4)\n",
    "plt.title('Exponential growth in percentage')\n",
    "plt.xlabel('Days since 2021-01-20')\n",
    "plt.ylabel('% positive COVID tests')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-ozone",
   "metadata": {},
   "source": [
    "We may ask - what if we have the same rise another two days? And, well, the staggering bad answer is that we would see 90% positive tests. Fortunately, the number of infections does not follow that logic but it is a warning that we can see in near future even higher numbers of new infected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-shuttle",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yfit_est = fitc[0] + fitc[1] * np.exp(fitc[2] * x[-1]+2)\n",
    "yfit_est"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-plaza",
   "metadata": {},
   "source": [
    "## What have we learned?\n",
    "\n",
    "1. We have got to know how to include packages\n",
    "2. how to load data\n",
    "3. how to inspect data textual/tabular and graphical\n",
    "4. how to sclice out parts of interest\n",
    "5. how to use different languages (or kernels) in a notebook\n",
    "6. how to formulate and proove a hypothesis\n",
    "7. how to fit a model (here using R)\n",
    "8. how to make some prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-giving",
   "metadata": {},
   "source": [
    "## What next?\n",
    "\n",
    "The next steps are to explore how to use some basic Python constructs, Pandas, numpy and matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-lithuania",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
